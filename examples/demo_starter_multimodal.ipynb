{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c79c38-38a3-40f3-ba2e-250649347d63",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_parse/blob/main/examples/demo_starter_multimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e081457",
   "metadata": {},
   "source": [
    "# Multimodal Parsing using LlamaParse\n",
    "\n",
    "This cookbook shows you how to use LlamaParse to parse any document with the multimodal capabilities of Multi-Modal LLMs from Anthropic/ OpenAI.\n",
    "\n",
    "LlamaParse allows you to plug in external, multimodal model vendors for parsing - we handle the error correction, validation, and scalability/reliability for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qOdqBxCS51Ow",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H_Vqcylb50vm",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e60ecf-519c-41fc-911b-765adaf8bad4",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Here we setup `LLAMA_CLOUD_API_KEY` for using `LlamaParse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9e532-1454-40e0-bbf0-fd442c350121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "\n",
    "# API access to llama-cloud\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"<YOUR LLAMACLOUD API KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LGwBNPNotZRQ",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "For this demonstration, we will use OpenAI's recent paper `Evaluation of OpenAI o1: Opportunities and Challenges of AGI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IjtKDQRLrylI",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-05 18:54:24--  https://arxiv.org/pdf/2409.18486\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13986265 (13M) [application/pdf]\n",
      "Saving to: ‘o1.pdf’\n",
      "\n",
      "o1.pdf              100%[===================>]  13.34M  11.8MB/s    in 1.1s    \n",
      "\n",
      "2024-12-05 18:54:26 (11.8 MB/s) - ‘o1.pdf’ saved [13986265/13986265]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://arxiv.org/pdf/2409.18486\" -O \"o1.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29a9d7-5bd9-4fb8-8ec1-4c128a748662",
   "metadata": {},
   "source": [
    "## Initialize LlamaParse\n",
    "\n",
    "Initialize LlamaParse in multimodal mode, and specify the vendor.\n",
    "\n",
    "**NOTE**: optionally you can specify the Anthropic/ OpenAI API key. If you choose to do so LlamaParse will only charge you 1 credit (0.3c) per page. \n",
    "\n",
    "\n",
    "Using your own API key may incur additional costs from your model provider and could result in failed pages or documents if you do not have sufficient usage limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc921729-3446-42ca-8e1b-a6fd26195ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_text_nodes(json_list: List[dict]):\n",
    "    text_nodes = []\n",
    "    for idx, page in enumerate(json_list):\n",
    "        text_node = TextNode(text=page[\"md\"], metadata={\"page\": page[\"page\"]})\n",
    "        text_nodes.append(text_node)\n",
    "    return text_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d6da6",
   "metadata": {},
   "source": [
    "### With anthropic-sonnet-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9d9cf-8189-4fcb-b34f-cde6cc0b59c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id dd9d5e0f-160e-486a-89a2-6005e5a1c2ac\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"anthropic-sonnet-3.5\",\n",
    "    target_pages=\"24\"\n",
    "    # invalidate_cache=True\n",
    ")\n",
    "json_objs = parser.get_json_result(\"o1.pdf\")\n",
    "json_list = json_objs[0][\"pages\"]\n",
    "docs = get_text_nodes(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c51b0-7878-48d7-9bc3-02b516500128",
   "metadata": {},
   "source": [
    "### With GPT-4o\n",
    "\n",
    "For comparison, we will also parse the document using GPT-4o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3f258-50ae-4988-b904-c105463a498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 6a4dea44-4f90-406b-b290-9e98620b1232\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser_gpt4o = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model=\"openai-gpt4o\",\n",
    "    target_pages=\"24\",\n",
    "    # invalidate_cache=True\n",
    ")\n",
    "json_objs_gpt4o = parser_gpt4o.get_json_result(\"o1.pdf\")\n",
    "json_list_gpt4o = json_objs_gpt4o[0][\"pages\"]\n",
    "docs_gpt4o = get_text_nodes(json_list_gpt4o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c20f7a-2901-4dd0-b635-a4b33c5664c1",
   "metadata": {},
   "source": [
    "### View Results\n",
    "\n",
    "Let's visualize the results along with the original document page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778698aa-da7e-4081-b3b5-0372f228536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 25\n",
      "\n",
      "| Participant_ID | clinical Description Reference |\n",
      "|-----------------|----------------------------------|\n",
      "| Attribute | Value | Basic Personal Information: Subject 098_S_0896 is a 72.0-year-old Female who has completed 15 years of education. The ethnicity is Not Hisp/Latino and race is White. Marital status is Married. Initially diagnosed as AD, as of the date 2007-10-24, the final diagnosis was Dementia. |\n",
      "| Age | 72.0 |\n",
      "| Sex | Female |\n",
      "| Education | 15 |\n",
      "| Race | White | Biomarker Measurements: The subject's genetic profile includes an ApoE4 status of 0.0... |\n",
      "| DX_bl | AD |\n",
      "| DX | Dementia |\n",
      "| ... | ... | Cognitive and Neurofunctional Assessments: The Mini-Mental State Examination score stands at 29.0. The Clinical Dementia Rating, sum of boxes, is 1.0. ADAS 11 and 13 scores are 4.67 and 4.67 respectively, with a score of 1.0 in delayed word recall... |\n",
      "| APOE4 | 1.0 |\n",
      "| TAU | 212.5 |\n",
      "| ... | ... |\n",
      "| MMSE | 29.0 | Volumetric Data: Under MRI conditions at a field strength of 1.5 Tesla MRI Tesla, using Cross Sectional FreeSurfer (FreeSurfer Version 4.3), the imaging data recorded includes ventricles volume at 54422.0, hippocampus volume at 6677.0, whole brain volume at 1147980.0, entorhinal cortex volume at 2782.0, fusiform gyrus volume at 19432.0, and middle temporal area volume at 24951.0. The intracranial volume measured is 1799580.0.... |\n",
      "| CDRSB | 0.0 |\n",
      "| ... | ... |\n",
      "| FLDSTRENG | 1.5 Tesla MRI |\n",
      "| Ventricles | 84599 |\n",
      "| Hippocampus | 5319 |\n",
      "| ... | ... |\n",
      "\n",
      "Figure 2: An example of a patient table and its corresponding clinical description.\n",
      "\n",
      "skills. Mathematics, as a highly structured and logic-driven discipline, provides an ideal testing ground for evaluating this reasoning ability. To investigate o1-preview's performance, we designed a series of tests covering various difficulty levels. We begin with high school-level math competition problems in this section, followed by college-level mathematics problems in the next section, allowing us to observe the model's logical reasoning across varying levels of complexity.\n",
      "\n",
      "In this section, we selected two primary areas of mathematics: algebra and counting and probability in this section. We chose these two topics because of their heavy reliance on problem-solving skills and their frequent use in assessing logical and abstract thinking [46]. The dataset used in testing is from the MATH dataset [46]. The problems in the dataset cover a wide range of subjects, including Prealgebra, Intermediate Algebra, Algebra, Geometry, Counting and Probability, Number Theory, and Precalculus. Each problem is categorized based on difficulty, ranked from level 1 to 5, according to the Art of Problem Solving (AoPS). The dataset mainly comprises problems from various high school math competitions, including the American Mathematics Competitions (AMC) 10 and 12, as well as the American Invitational Mathematics Examination (AIME), and other similar contests. Each problem comes with detailed reference solutions, allowing for a comprehensive comparison of o1-preview's solutions.\n",
      "\n",
      "In addition to evaluating the final answers produced by o1-preview, our analysis delves into the step-by-step reasoning process of the o1-preview's solutions. By comparing o1-preview's solutions with the dataset's solutions, we assess its ability to engage in logical reasoning, handle abstract problem-solving tasks, and apply structured approaches to reach correct answers. This deeper analysis offers insights into o1-preview's overall reasoning capabilities, using mathematics as a reliable indicator for logical and structured thought processes.\n"
     ]
    }
   ],
   "source": [
    "# using Sonnet-3.5\n",
    "print(docs[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511a30f-3efc-4142-9668-7dc056a24d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 25\n",
      "\n",
      "\n",
      "| Participant_ID | clinical Description Reference |\n",
      "|----------------|--------------------------------|\n",
      "| **Attribute**  | **Value**                      |\n",
      "| Age            | 72.0                           |\n",
      "| Sex            | Female                         |\n",
      "| Education      | 15                             |\n",
      "| Race           | White                          |\n",
      "| DX_bl          | AD                             |\n",
      "| DX             | Dementia                       |\n",
      "| ...            | ...                            |\n",
      "| APOE4          | 1.0                            |\n",
      "| TAU            | 212.5                          |\n",
      "| ...            | ...                            |\n",
      "| MMSE           | 29.0                           |\n",
      "| CDRSB          | 0.0                            |\n",
      "| ...            | ...                            |\n",
      "| FLDSTRENG      | 1.5 Tesla MRI                  |\n",
      "| Ventricles     | 84599                          |\n",
      "| Hippocampus    | 5319                           |\n",
      "| ...            | ...                            |\n",
      "\n",
      "**Basic Personal Information:** Subject 098_S_0896 is a 72.0-year-old Female who has completed 15 years of education. The ethnicity is Not Hisp/Latino and race is White. Marital status is Married. Initially diagnosed as AD, as of the date 2007-10-24, the final diagnosis was Dementia.\n",
      "\n",
      "**Biomarker Measurements:** The subject's genetic profile includes an ApoE4 status of 0.0...\n",
      "\n",
      "**Cognitive and Neurofunctional Assessments:** The Mini-Mental State Examination score stands at 29.0. The Clinical Dementia Rating, sum of boxes, is 1.0. ADAS 11 and 13 scores are 4.67 and 4.67 respectively, with a score of 1.0 in delayed word recall...\n",
      "\n",
      "**Volumetric Data:** Under MRI conditions at a field strength of 1.5 Tesla MRI Tesla, using Cross-Sectional FreeSurfer (FreeSurfer Version 4.3), the imaging data recorded includes ventricles volume at 84422.0, hippocampus volume at 6677.0, whole brain volume at 1147980.0, entorhinal cortex volume at 27820.0, fusiform gyrus volume at 19432.0, and middle temporal area volume at 24951.0. The intracranial volume measured is 1799580.0...\n",
      "\n",
      "Figure 2: An example of a patient table and its corresponding clinical description.\n",
      "\n",
      "----\n",
      "\n",
      "Skills. Mathematics, as a highly structured and logic-driven discipline, provides an ideal testing ground for evaluating this reasoning ability. To investigate o1-preview’s performance, we designed a series of tests covering various difficulty levels. We begin with high school-level math competition problems in this section, followed by college-level mathematics problems in the next section, allowing us to observe the model’s logical reasoning across varying levels of complexity.\n",
      "\n",
      "In this section, we selected two primary areas of mathematics: algebra and counting and probability in this section. We chose these two topics because of their heavy reliance on problem-solving skills and their frequent use in assessing logical and abstract thinking [46]. The dataset used in testing is from the MATH dataset [46]. The problems in the dataset cover a wide range of subjects, including Prealgebra, Intermediate Algebra, Algebra, Geometry, Counting and Probability, Number Theory, and Precalculus. Each problem is categorized based on difficulty, ranked from level 1 to 5, according to the Art of Problem Solving (AoPS). The dataset mainly comprises problems from various high school math competitions, including the American Mathematics Competitions (AMC) 10 and 12, as well as the American Invitational Mathematics Examination (AIME), and other similar contests. Each problem comes with detailed reference solutions, allowing for a comprehensive comparison of o1-preview’s solutions.\n",
      "\n",
      "In addition to evaluating the final answers produced by o1-preview, our analysis delves into the step-by-step reasoning process of the o1-preview’s solutions. By comparing o1-preview’s solutions with the dataset’s solutions, we assess its ability to engage in logical reasoning, handle abstract problem-solving tasks, and apply structured approaches to reach correct answers. This deeper analysis offers insights into o1-preview’s overall reasoning capabilities, using mathematics as a reliable indicator for logical and structured thought processes.\n"
     ]
    }
   ],
   "source": [
    "# using GPT-4o\n",
    "print(docs_gpt4o[0].get_content(metadata_mode=\"all\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llamacloud",
   "language": "python",
   "name": "llamacloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
